{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import coo_matrix\n",
    "import xgboost as xgb\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import uniform\n",
    "import ast\n",
    "from sklearn.metrics import accuracy_score\n",
    "random_state = 42\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto  (864459, 34)\n",
      "Tamaño del conjunto  (50000, 34)\n",
      "Tamaño del conjunto  (1139639, 33)\n"
     ]
    }
   ],
   "source": [
    "datosreducido = pd.read_csv('/Users/ionikullock/Desktop/UTDT-Tecnología Digital/TD VI/Trabajo práctico 2/Datos/data_reducido.csv')  #  dataset\n",
    "print(\"Tamaño del conjunto \", datosreducido.shape)\n",
    "\n",
    "data50k = datosreducido.sample(n=50000, random_state=42)\n",
    "print(\"Tamaño del conjunto \", data50k.shape)\n",
    "\n",
    "validation_data_for_submit = pd.read_csv('/Users/ionikullock/Desktop/UTDT-Tecnología Digital/TD VI/Trabajo práctico 2/Datos/validation_data_processed_for_datos_reducido.csv')\n",
    "print(\"Tamaño del conjunto \", validation_data_for_submit.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando One-Hot Encoding...\n",
      "Codificando columna: action_categorical_0\n",
      "Forma después de codificar action_categorical_0: (50000, 42)\n",
      "Codificando columna: action_categorical_1\n",
      "Forma después de codificar action_categorical_1: (50000, 55)\n",
      "Codificando columna: action_categorical_2\n",
      "Forma después de codificar action_categorical_2: (50000, 153)\n",
      "Codificando columna: action_categorical_3\n",
      "Forma después de codificar action_categorical_3: (50000, 169)\n",
      "Codificando columna: action_categorical_4\n",
      "Forma después de codificar action_categorical_4: (50000, 729)\n",
      "Codificando columna: auction_categorical_0\n",
      "Forma después de codificar auction_categorical_0: (50000, 1168)\n",
      "Codificando columna: auction_categorical_11\n",
      "Forma después de codificar auction_categorical_11: (50000, 5144)\n",
      "Codificando columna: auction_categorical_12\n",
      "Forma después de codificar auction_categorical_12: (50000, 6912)\n",
      "Codificando columna: auction_categorical_3\n",
      "Forma después de codificar auction_categorical_3: (50000, 42697)\n",
      "Codificando columna: auction_categorical_7\n",
      "Forma después de codificar auction_categorical_7: (50000, 45166)\n",
      "Codificando columna: auction_categorical_8\n",
      "Forma después de codificar auction_categorical_8: (50000, 45175)\n",
      "Codificando columna: auction_categorical_9\n",
      "Forma después de codificar auction_categorical_9: (50000, 47730)\n",
      "Codificando columna: creative_categorical_0\n",
      "Forma después de codificar creative_categorical_0: (50000, 48411)\n",
      "Codificando columna: creative_categorical_11\n",
      "Forma después de codificar creative_categorical_11: (50000, 48412)\n",
      "Codificando columna: creative_categorical_12\n",
      "Forma después de codificar creative_categorical_12: (50000, 48427)\n",
      "Codificando columna: creative_categorical_2\n",
      "Forma después de codificar creative_categorical_2: (50000, 48438)\n",
      "Codificando columna: creative_categorical_4\n",
      "Forma después de codificar creative_categorical_4: (50000, 48441)\n",
      "Codificando columna: creative_categorical_5\n",
      "Forma después de codificar creative_categorical_5: (50000, 48453)\n",
      "Codificando columna: creative_categorical_6\n",
      "Forma después de codificar creative_categorical_6: (50000, 48623)\n",
      "Codificando columna: creative_categorical_7\n",
      "Forma después de codificar creative_categorical_7: (50000, 48631)\n",
      "Codificando columna: creative_categorical_8\n",
      "Forma después de codificar creative_categorical_8: (50000, 48635)\n",
      "Codificando columna: creative_categorical_9\n",
      "Forma después de codificar creative_categorical_9: (50000, 48637)\n",
      "Codificando columna: device_id_type\n",
      "Forma después de codificar device_id_type: (50000, 48639)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3983968912.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame después del MultiLabel OHE:\n",
      "Forma después de codificar train: (50000, 48639)\n"
     ]
    }
   ],
   "source": [
    "def apply_one_hot_encoding(df, columns):\n",
    "    print(\"Aplicando One-Hot Encoding...\")\n",
    "    df_encoded = df.copy()\n",
    "    for col in columns:\n",
    "        if col in df_encoded.columns:\n",
    "            # Asegurarse de que la columna esté en formato string\n",
    "            df_encoded[col] = df_encoded[col].astype(str)\n",
    "            \n",
    "            print(f\"Codificando columna: {col}\")\n",
    "            df_encoded = pd.get_dummies(df_encoded, columns=[col], sparse=True, dummy_na=False, dtype=int)\n",
    "            print(f\"Forma después de codificar {col}: {df_encoded.shape}\")\n",
    "        else:\n",
    "            print(f\"La columna '{col}' no está en el DataFrame\")\n",
    "    return df_encoded\n",
    "\n",
    "def convert_string_to_list(df, list_columns):\n",
    "    for col in list_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "        else:\n",
    "            print(f\"La columna '{col}' no está en el DataFrame\")\n",
    "    return df\n",
    "\n",
    "def apply_multilabel_ohe(df, list_columns):\n",
    "    df = convert_string_to_list(df, list_columns)\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    for col in list_columns:\n",
    "        if col in df_encoded.columns:\n",
    "            unique_values = set()\n",
    "            df_encoded[col].dropna().apply(lambda x: unique_values.update(map(str, x)) if isinstance(x, list) else None)\n",
    "            \n",
    "            # Crear un DataFrame de OHE para esta columna\n",
    "            ohe_df = pd.DataFrame()\n",
    "            for value in unique_values:\n",
    "                ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
    "            \n",
    "            # Concatenar con el DataFrame original\n",
    "            df_encoded = pd.concat([df_encoded, ohe_df], axis=1)\n",
    "            \n",
    "            # Eliminar la columna original con listas si ya no es necesaria\n",
    "            df_encoded = df_encoded.drop(columns=[col])\n",
    "        else:\n",
    "            print(f\"La columna '{col}' no está en el DataFrame\")\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "columns_to_encode = [\n",
    "    'action_categorical_0', 'action_categorical_1', 'action_categorical_2', \n",
    "    'action_categorical_3', 'action_categorical_4',\n",
    "    'auction_categorical_0', 'auction_categorical_11', 'auction_categorical_12', \n",
    "    'auction_categorical_3', 'auction_categorical_7', 'auction_categorical_8', \n",
    "    'auction_categorical_9', 'creative_categorical_0', \n",
    "    'creative_categorical_11', 'creative_categorical_12', 'creative_categorical_2', \n",
    "    'creative_categorical_4', 'creative_categorical_5', 'creative_categorical_6', \n",
    "    'creative_categorical_7', 'creative_categorical_8', 'creative_categorical_9', \n",
    "    'device_id_type'\n",
    "]\n",
    "\n",
    "# Columnas con listas para OHE\n",
    "list_columns = ['action_list_1', 'action_list_2', 'auction_list_0']\n",
    "\n",
    "# Aplicar codificación one-hot a las columnas categóricas\n",
    "data_OHE_Cat = apply_one_hot_encoding(data50k, columns_to_encode)\n",
    "\n",
    "# Aplicar OHE a las columnas de listas\n",
    "data_OHE_Cat_List = apply_multilabel_ohe(data_OHE_Cat, list_columns)\n",
    "#Valid_OHE_Cat_List = apply_multilabel_ohe(Valid_OHE_Cat, list_columns)\n",
    "\n",
    "print(\"DataFrame después del MultiLabel OHE:\")\n",
    "print(f\"Forma después de codificar train: {data_OHE_Cat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en la columna Label: [0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_age</th>\n",
       "      <th>auction_bidfloor</th>\n",
       "      <th>auction_time</th>\n",
       "      <th>creative_height</th>\n",
       "      <th>creative_width</th>\n",
       "      <th>has_video</th>\n",
       "      <th>timezone_offset</th>\n",
       "      <th>action_categorical_0_11b7af3d</th>\n",
       "      <th>action_categorical_0_604d011f</th>\n",
       "      <th>action_categorical_0_6b5513a4</th>\n",
       "      <th>...</th>\n",
       "      <th>IAB9-30</th>\n",
       "      <th>IAB7-2</th>\n",
       "      <th>IAB7-10</th>\n",
       "      <th>IAB10-3</th>\n",
       "      <th>IAB6-4</th>\n",
       "      <th>IAB19-3</th>\n",
       "      <th>IAB6-9</th>\n",
       "      <th>IAB18</th>\n",
       "      <th>IAB17-39</th>\n",
       "      <th>lifestyle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666392</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.516143e+09</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675483</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>1.516539e+09</td>\n",
       "      <td>250.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381289</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.516390e+09</td>\n",
       "      <td>250.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174376</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.559000</td>\n",
       "      <td>1.516374e+09</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220432</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.516380e+09</td>\n",
       "      <td>250.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631126</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.516479e+09</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72307</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.516206e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90504</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.516473e+09</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521083</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.516557e+09</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747801</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.516263e+09</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 48995 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        auction_age  auction_bidfloor  auction_time  creative_height  \\\n",
       "666392          NaN          0.020000  1.516143e+09             50.0   \n",
       "675483          NaN          0.310000  1.516539e+09            250.0   \n",
       "381289          NaN          0.070000  1.516390e+09            250.0   \n",
       "174376          NaN          0.559000  1.516374e+09             50.0   \n",
       "220432         31.0          0.020000  1.516380e+09            250.0   \n",
       "...             ...               ...           ...              ...   \n",
       "631126          NaN          0.100000  1.516479e+09             50.0   \n",
       "72307          39.0          0.850000  1.516206e+09              NaN   \n",
       "90504          16.0          0.020000  1.516473e+09             50.0   \n",
       "521083          NaN          0.307692  1.516557e+09             50.0   \n",
       "747801         34.0          0.020000  1.516263e+09             50.0   \n",
       "\n",
       "        creative_width  has_video  timezone_offset  \\\n",
       "666392           320.0      False              1.0   \n",
       "675483           300.0      False              4.0   \n",
       "381289           300.0      False              1.0   \n",
       "174376           320.0      False              1.0   \n",
       "220432           300.0      False              4.0   \n",
       "...                ...        ...              ...   \n",
       "631126           320.0      False              1.0   \n",
       "72307              NaN      False              1.0   \n",
       "90504            320.0      False              1.0   \n",
       "521083           320.0      False              1.0   \n",
       "747801           320.0      False             10.0   \n",
       "\n",
       "        action_categorical_0_11b7af3d  action_categorical_0_604d011f  \\\n",
       "666392                              0                              0   \n",
       "675483                              0                              1   \n",
       "381289                              0                              0   \n",
       "174376                              1                              0   \n",
       "220432                              0                              1   \n",
       "...                               ...                            ...   \n",
       "631126                              0                              0   \n",
       "72307                               0                              0   \n",
       "90504                               0                              0   \n",
       "521083                              0                              0   \n",
       "747801                              0                              0   \n",
       "\n",
       "        action_categorical_0_6b5513a4  ...  IAB9-30  IAB7-2  IAB7-10  IAB10-3  \\\n",
       "666392                              0  ...        0       0        0        0   \n",
       "675483                              0  ...        0       0        0        0   \n",
       "381289                              0  ...        0       0        0        0   \n",
       "174376                              0  ...        0       0        0        0   \n",
       "220432                              0  ...        0       0        0        0   \n",
       "...                               ...  ...      ...     ...      ...      ...   \n",
       "631126                              0  ...        0       0        0        0   \n",
       "72307                               0  ...        0       0        0        0   \n",
       "90504                               0  ...        0       0        0        0   \n",
       "521083                              0  ...        0       0        0        0   \n",
       "747801                              0  ...        0       0        0        0   \n",
       "\n",
       "        IAB6-4  IAB19-3  IAB6-9  IAB18  IAB17-39  lifestyle  \n",
       "666392       0        0       0      0         0          0  \n",
       "675483       0        0       0      0         0          0  \n",
       "381289       0        0       0      0         0          0  \n",
       "174376       0        0       0      0         0          0  \n",
       "220432       0        0       0      0         0          0  \n",
       "...        ...      ...     ...    ...       ...        ...  \n",
       "631126       0        0       0      0         0          0  \n",
       "72307        0        0       0      0         0          1  \n",
       "90504        0        0       0      0         0          0  \n",
       "521083       0        0       0      0         0          0  \n",
       "747801       0        0       0      0         0          0  \n",
       "\n",
       "[50000 rows x 48995 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_OHE_Cat_List[['Label']].copy() # Usamos copy para no modificar un view abajo, ya que genera un warning.\n",
    "y\n",
    "unique_labels = data_OHE_Cat_List['Label'].unique()\n",
    "print(f'Valores únicos en la columna Label: {unique_labels}')\n",
    "y[y['Label'] == 0. ] = 0\n",
    "y[y['Label'] == 1.] = 1\n",
    "y['Label'] = y['Label'].fillna(0)\n",
    "y['Label'] = y['Label'].astype(int)\n",
    "X = data_OHE_Cat_List.drop('Label', axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n",
      "Cantidad de datos de entrenamiento: 35000\n",
      "Cantidad de datos de validación: 7500\n",
      "Cantidad de datos de prueba: 7500\n",
      "Cantidad de datos de train: 35000\n",
      "Cantidad de datos de validación: 7500\n",
      "Cantidad de datos de test: 7500\n"
     ]
    }
   ],
   "source": [
    "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y,\n",
    "                                                  train_size=0.7,\n",
    "                                                  random_state=42,\n",
    "                                                  stratify=y)\n",
    "print(\"ready\")\n",
    "\n",
    "# Dividir el resto en validación y prueba\n",
    "X_val, X_test, Y_val, y_test = train_test_split(X_tmp, y_tmp,\n",
    "                                                train_size=0.5,\n",
    "                                                random_state=42,\n",
    "                                                stratify=y_tmp)\n",
    "\n",
    "print(f'Cantidad de datos de entrenamiento: {len(X_train)}')\n",
    "print(f'Cantidad de datos de validación: {len(X_val)}')\n",
    "print(f'Cantidad de datos de prueba: {len(X_test)}')\n",
    "\n",
    "val_test_size = 0.3 # Proporción de la suma del test de validación y del de test.\n",
    "X_train, X_tmp, Y_train, Y_tmp = train_test_split(X, y,\n",
    "                                                  train_size = 0.7,\n",
    "                                                  random_state = 42,\n",
    "                                                  stratify = y)\n",
    "\n",
    "X_val, X_test, Y_val, y_test = train_test_split(X_tmp, y_tmp,\n",
    "                                                train_size=0.5,\n",
    "                                                random_state= 42,\n",
    "                                                stratify=y_tmp)\n",
    "print(f'Cantidad de datos de train: {len(X_train)}')\n",
    "print(f'Cantidad de datos de validación: {len(X_val)}')\n",
    "print(f'Cantidad de datos de test: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auction_age                                float64\n",
      "auction_bidfloor                           float64\n",
      "auction_time                               float64\n",
      "creative_height                            float64\n",
      "creative_width                             float64\n",
      "                                        ...       \n",
      "auction_categorical_0_6e069bec    Sparse[int64, 0]\n",
      "auction_categorical_0_6e74066f    Sparse[int64, 0]\n",
      "auction_categorical_0_6e9ad7fd    Sparse[int64, 0]\n",
      "auction_categorical_0_6eba7824    Sparse[int64, 0]\n",
      "auction_categorical_0_707fbf0e    Sparse[int64, 0]\n",
      "Length: 900, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes.head(900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGBoost classifier\n",
    "clf_xgb = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                            seed=42,\n",
    "                            eval_metric='auc',  # You can also use 'logloss' for binary classification\n",
    "                            use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:39:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.75379\n",
      "[1]\tvalidation_0-auc:0.75646\n",
      "[2]\tvalidation_0-auc:0.77839\n",
      "[3]\tvalidation_0-auc:0.78123\n",
      "[4]\tvalidation_0-auc:0.78308\n",
      "[5]\tvalidation_0-auc:0.78306\n",
      "[6]\tvalidation_0-auc:0.78143\n",
      "[7]\tvalidation_0-auc:0.79876\n",
      "[8]\tvalidation_0-auc:0.80058\n",
      "[9]\tvalidation_0-auc:0.79576\n",
      "[10]\tvalidation_0-auc:0.79668\n",
      "[11]\tvalidation_0-auc:0.79923\n",
      "[12]\tvalidation_0-auc:0.79970\n",
      "[13]\tvalidation_0-auc:0.80074\n",
      "[14]\tvalidation_0-auc:0.79801\n",
      "[15]\tvalidation_0-auc:0.79550\n",
      "[16]\tvalidation_0-auc:0.79689\n",
      "[17]\tvalidation_0-auc:0.79732\n",
      "[18]\tvalidation_0-auc:0.79828\n",
      "[19]\tvalidation_0-auc:0.79928\n",
      "[20]\tvalidation_0-auc:0.80062\n",
      "[21]\tvalidation_0-auc:0.80168\n",
      "[22]\tvalidation_0-auc:0.79984\n",
      "[23]\tvalidation_0-auc:0.80029\n",
      "[24]\tvalidation_0-auc:0.80053\n",
      "[25]\tvalidation_0-auc:0.80152\n",
      "[26]\tvalidation_0-auc:0.80294\n",
      "[27]\tvalidation_0-auc:0.80248\n",
      "[28]\tvalidation_0-auc:0.80150\n",
      "[29]\tvalidation_0-auc:0.79903\n",
      "[30]\tvalidation_0-auc:0.79959\n",
      "[31]\tvalidation_0-auc:0.80020\n",
      "[32]\tvalidation_0-auc:0.80016\n",
      "[33]\tvalidation_0-auc:0.80025\n",
      "[34]\tvalidation_0-auc:0.80042\n",
      "[35]\tvalidation_0-auc:0.80008\n",
      "[36]\tvalidation_0-auc:0.79968\n",
      "[37]\tvalidation_0-auc:0.79981\n",
      "[38]\tvalidation_0-auc:0.79955\n",
      "[39]\tvalidation_0-auc:0.79903\n",
      "[40]\tvalidation_0-auc:0.79981\n",
      "[41]\tvalidation_0-auc:0.80067\n",
      "[42]\tvalidation_0-auc:0.80134\n",
      "[43]\tvalidation_0-auc:0.80140\n",
      "[44]\tvalidation_0-auc:0.80130\n",
      "[45]\tvalidation_0-auc:0.80086\n",
      "[46]\tvalidation_0-auc:0.79925\n",
      "[47]\tvalidation_0-auc:0.79735\n",
      "[48]\tvalidation_0-auc:0.79682\n",
      "[49]\tvalidation_0-auc:0.79747\n",
      "[50]\tvalidation_0-auc:0.79764\n",
      "[51]\tvalidation_0-auc:0.79738\n",
      "[52]\tvalidation_0-auc:0.79773\n",
      "[53]\tvalidation_0-auc:0.79796\n",
      "[54]\tvalidation_0-auc:0.79850\n",
      "[55]\tvalidation_0-auc:0.79874\n",
      "[56]\tvalidation_0-auc:0.79987\n",
      "[57]\tvalidation_0-auc:0.80049\n",
      "[58]\tvalidation_0-auc:0.80011\n",
      "[59]\tvalidation_0-auc:0.79977\n",
      "[60]\tvalidation_0-auc:0.79937\n",
      "[61]\tvalidation_0-auc:0.79939\n",
      "[62]\tvalidation_0-auc:0.79907\n",
      "[63]\tvalidation_0-auc:0.79725\n",
      "[64]\tvalidation_0-auc:0.79691\n",
      "[65]\tvalidation_0-auc:0.79606\n",
      "[66]\tvalidation_0-auc:0.79612\n",
      "[67]\tvalidation_0-auc:0.79699\n",
      "[68]\tvalidation_0-auc:0.79692\n",
      "[69]\tvalidation_0-auc:0.79784\n",
      "[70]\tvalidation_0-auc:0.79774\n",
      "[71]\tvalidation_0-auc:0.79758\n",
      "[72]\tvalidation_0-auc:0.79796\n",
      "[73]\tvalidation_0-auc:0.79834\n",
      "[74]\tvalidation_0-auc:0.79898\n",
      "[75]\tvalidation_0-auc:0.79875\n",
      "[76]\tvalidation_0-auc:0.79886\n",
      "[77]\tvalidation_0-auc:0.79917\n",
      "[78]\tvalidation_0-auc:0.79830\n",
      "[79]\tvalidation_0-auc:0.79830\n",
      "[80]\tvalidation_0-auc:0.79816\n",
      "[81]\tvalidation_0-auc:0.79809\n",
      "[82]\tvalidation_0-auc:0.79830\n",
      "[83]\tvalidation_0-auc:0.79813\n",
      "[84]\tvalidation_0-auc:0.79717\n",
      "[85]\tvalidation_0-auc:0.79665\n",
      "[86]\tvalidation_0-auc:0.79742\n",
      "[87]\tvalidation_0-auc:0.79700\n",
      "[88]\tvalidation_0-auc:0.79696\n",
      "[89]\tvalidation_0-auc:0.79727\n",
      "[90]\tvalidation_0-auc:0.79679\n",
      "[91]\tvalidation_0-auc:0.79469\n",
      "[92]\tvalidation_0-auc:0.79246\n",
      "[93]\tvalidation_0-auc:0.79208\n",
      "[94]\tvalidation_0-auc:0.78931\n",
      "[95]\tvalidation_0-auc:0.79154\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m X_test_sparse \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X_test)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Ahora puedes usar XGBoost con matrices sparse\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mclf_xgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[0;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/training.py:182\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    185\u001b[0m bst \u001b[38;5;241m=\u001b[39m cb_container\u001b[38;5;241m.\u001b[39mafter_training(bst)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/callback.py:258\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m name\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset name should not contain `-`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 258\u001b[0m score: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_margin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m metric_score \u001b[38;5;241m=\u001b[39m _parse_eval_str(score)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_history(metric_score, epoch)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/core.py:2212\u001b[0m, in \u001b[0;36mBooster.eval_set\u001b[0;34m(self, evals, iteration, feval, output_margin)\u001b[0m\n\u001b[1;32m   2209\u001b[0m evnames \u001b[38;5;241m=\u001b[39m c_array(ctypes\u001b[38;5;241m.\u001b[39mc_char_p, [c_str(d[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m evals])\n\u001b[1;32m   2210\u001b[0m msg \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p()\n\u001b[1;32m   2211\u001b[0m _check_call(\n\u001b[0;32m-> 2212\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterEvalOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc_bst_ulong\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2220\u001b[0m )\n\u001b[1;32m   2221\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m msg\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2222\u001b[0m res \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdecode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "X_train_sparse = sp.csr_matrix(X_train)\n",
    "X_val_sparse = sp.csr_matrix(X_val)\n",
    "X_test_sparse = sp.csr_matrix(X_test)\n",
    "\n",
    "# Ahora puedes usar XGBoost con matrices sparse\n",
    "clf_xgb.fit(X_train_sparse, y_train, eval_set=[(X_val_sparse, Y_val)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m eval_data_sparse \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(eval_data_imputed)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Hacer predicciones con el modelo XGBoost entrenado\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m y_preds \u001b[38;5;241m=\u001b[39m \u001b[43mclf_xgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_data_sparse\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Obtener la probabilidad de la clase positiva (1)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Crear el DataFrame para el envío a Kaggle\u001b[39;00m\n\u001b[1;32m     24\u001b[0m submission_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: eval_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_preds\n\u001b[1;32m     27\u001b[0m })\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/sklearn.py:1644\u001b[0m, in \u001b[0;36mXGBClassifier.predict_proba\u001b[0;34m(self, X, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1642\u001b[0m     class_prob \u001b[38;5;241m=\u001b[39m softmax(raw_predt, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m class_prob\n\u001b[0;32m-> 1644\u001b[0m class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _cls_predict_proba(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_, class_probs, np\u001b[38;5;241m.\u001b[39mvstack)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/sklearn.py:1186\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1186\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[1;32m   1187\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   1188\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[1;32m   1189\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1190\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1191\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[1;32m   1192\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[1;32m   1193\u001b[0m         )\n\u001b[1;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[1;32m   1195\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/sklearn.py:805\u001b[0m, in \u001b[0;36mXGBModel.get_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__():\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[0;32m--> 805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to call fit or load_model beforehand\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\n",
      "\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Cargar los datos de evaluación (test)\n",
    "eval_data = pd.read_csv(\"/Users/ionikullock/Desktop/UTDT-Tecnología Digital/TD VI/Trabajo práctico 2/Datos/ctr_test.csv\")\n",
    "\n",
    "\n",
    "# Procesar los datos de test (seleccionando solo las columnas numéricas, como en el entrenamiento)\n",
    "eval_data_num = eval_data.select_dtypes(include='number')\n",
    "\n",
    "# Imputar valores faltantes, si es necesario (usa la misma estrategia que en entrenamiento)\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "eval_data_imputed = imputer.fit_transform(eval_data_num.drop(columns=[\"id\"]))\n",
    "\n",
    "# Convertir los datos a formato sparse para ser usados en el modelo XGBoost\n",
    "eval_data_sparse = sp.csr_matrix(eval_data_imputed)\n",
    "\n",
    "# Hacer predicciones con el modelo XGBoost entrenado\n",
    "y_preds = clf_xgb.predict_proba(eval_data_sparse)[:, 1]  # Obtener la probabilidad de la clase positiva (1)\n",
    "\n",
    "# Crear el DataFrame para el envío a Kaggle\n",
    "submission_df = pd.DataFrame({\n",
    "    \"id\": eval_data[\"id\"],\n",
    "    \"Label\": y_preds\n",
    "})\n",
    "\n",
    "# Convertir el ID a entero (según el formato requerido por Kaggle)\n",
    "submission_df[\"id\"] = submission_df[\"id\"].astype(int)\n",
    "\n",
    "# Guardar el archivo CSV para enviar a Kaggle\n",
    "submission_df.to_csv(\"xgboost_model_submission.csv\", sep=\",\", index=False)\n",
    "\n",
    "print(\"Archivo de predicción creado: xgboost_model_submission.csv\")\n",
    "\n",
    "print(\"Archivo de predicción creado: xgboost_model_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TD6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
