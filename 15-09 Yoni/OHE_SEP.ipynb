{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import coo_matrix\n",
    "import xgboost as xgb\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import uniform\n",
    "import ast\n",
    "from sklearn.metrics import accuracy_score\n",
    "random_state = 42\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto  (864459, 34)\n",
      "Tamaño del conjunto  (50000, 34)\n",
      "Tamaño del conjunto  (1139639, 33)\n"
     ]
    }
   ],
   "source": [
    "datosreducido = pd.read_csv('/Users/ionikullock/Desktop/UTDT-Tecnología Digital/TD VI/Trabajo práctico 2/Datos/data_reducido.csv')  #  dataset\n",
    "print(\"Tamaño del conjunto \", datosreducido.shape)\n",
    "\n",
    "data50k = datosreducido.sample(n=50000, random_state=42)\n",
    "print(\"Tamaño del conjunto \", data50k.shape)\n",
    "\n",
    "validation_data_for_submit = pd.read_csv('/Users/ionikullock/Desktop/UTDT-Tecnología Digital/TD VI/Trabajo práctico 2/Datos/validation_data_processed_for_datos_reducido.csv')\n",
    "print(\"Tamaño del conjunto \", validation_data_for_submit.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando One-Hot Encoding...\n",
      "Codificando columna: action_categorical_0\n",
      "Forma después de codificar action_categorical_0: (50000, 42)\n",
      "Codificando columna: action_categorical_1\n",
      "Forma después de codificar action_categorical_1: (50000, 55)\n",
      "Codificando columna: action_categorical_2\n",
      "Forma después de codificar action_categorical_2: (50000, 153)\n",
      "Codificando columna: action_categorical_3\n",
      "Forma después de codificar action_categorical_3: (50000, 169)\n",
      "Codificando columna: action_categorical_4\n",
      "Forma después de codificar action_categorical_4: (50000, 729)\n",
      "Codificando columna: auction_categorical_0\n",
      "Forma después de codificar auction_categorical_0: (50000, 1168)\n",
      "Codificando columna: auction_categorical_11\n",
      "Forma después de codificar auction_categorical_11: (50000, 5144)\n",
      "Codificando columna: auction_categorical_12\n",
      "Forma después de codificar auction_categorical_12: (50000, 6912)\n",
      "Codificando columna: auction_categorical_3\n",
      "Forma después de codificar auction_categorical_3: (50000, 42697)\n",
      "Codificando columna: auction_categorical_7\n",
      "Forma después de codificar auction_categorical_7: (50000, 45166)\n",
      "Codificando columna: auction_categorical_8\n",
      "Forma después de codificar auction_categorical_8: (50000, 45175)\n",
      "Codificando columna: auction_categorical_9\n",
      "Forma después de codificar auction_categorical_9: (50000, 47730)\n",
      "Codificando columna: creative_categorical_0\n",
      "Forma después de codificar creative_categorical_0: (50000, 48411)\n",
      "Codificando columna: creative_categorical_11\n",
      "Forma después de codificar creative_categorical_11: (50000, 48412)\n",
      "Codificando columna: creative_categorical_12\n",
      "Forma después de codificar creative_categorical_12: (50000, 48427)\n",
      "Codificando columna: creative_categorical_2\n",
      "Forma después de codificar creative_categorical_2: (50000, 48438)\n",
      "Codificando columna: creative_categorical_4\n",
      "Forma después de codificar creative_categorical_4: (50000, 48441)\n",
      "Codificando columna: creative_categorical_5\n",
      "Forma después de codificar creative_categorical_5: (50000, 48453)\n",
      "Codificando columna: creative_categorical_6\n",
      "Forma después de codificar creative_categorical_6: (50000, 48623)\n",
      "Codificando columna: creative_categorical_7\n",
      "Forma después de codificar creative_categorical_7: (50000, 48631)\n",
      "Codificando columna: creative_categorical_8\n",
      "Forma después de codificar creative_categorical_8: (50000, 48635)\n",
      "Codificando columna: creative_categorical_9\n",
      "Forma después de codificar creative_categorical_9: (50000, 48637)\n",
      "Codificando columna: device_id_type\n",
      "Forma después de codificar device_id_type: (50000, 48639)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
      "/var/folders/m6/yrlm4ckj0r71yq2s7_1v54kh0000gn/T/ipykernel_51892/3386192874.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame después del MultiLabel OHE:\n",
      "Forma después de codificar train: (50000, 48639)\n"
     ]
    }
   ],
   "source": [
    "def apply_one_hot_encoding(df, columns):\n",
    "    print(\"Aplicando One-Hot Encoding...\")\n",
    "    df_encoded = df.copy()\n",
    "    for col in columns:\n",
    "        if col in df_encoded.columns:\n",
    "            # Asegurarse de que la columna esté en formato string\n",
    "            df_encoded[col] = df_encoded[col].astype(str)\n",
    "            \n",
    "            print(f\"Codificando columna: {col}\")\n",
    "            df_encoded = pd.get_dummies(df_encoded, columns=[col], sparse=True, dummy_na=False, dtype=int)\n",
    "            print(f\"Forma después de codificar {col}: {df_encoded.shape}\")\n",
    "        else:\n",
    "            print(f\"La columna '{col}' no está en el DataFrame\")\n",
    "    return df_encoded\n",
    "\n",
    "def convert_string_to_list(df, list_columns):\n",
    "    for col in list_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "        else:\n",
    "            print(f\"La columna '{col}' no está en el DataFrame\")\n",
    "    return df\n",
    "\n",
    "def apply_multilabel_ohe(df, list_columns):\n",
    "    df = convert_string_to_list(df, list_columns)\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    for col in list_columns:\n",
    "        if col in df_encoded.columns:\n",
    "            unique_values = set()\n",
    "            df_encoded[col].dropna().apply(lambda x: unique_values.update(map(str, x)) if isinstance(x, list) else None)\n",
    "            \n",
    "            # Crear un DataFrame de OHE para esta columna\n",
    "            ohe_df = pd.DataFrame()\n",
    "            for value in unique_values:\n",
    "                ohe_df[value] = df_encoded[col].apply(lambda x: 1 if isinstance(x, list) and str(value) in map(str, x) else 0)\n",
    "            \n",
    "            # Concatenar con el DataFrame original\n",
    "            df_encoded = pd.concat([df_encoded, ohe_df], axis=1)\n",
    "            \n",
    "            # Eliminar la columna original con listas si ya no es necesaria\n",
    "            df_encoded = df_encoded.drop(columns=[col])\n",
    "        else:\n",
    "            print(f\"La columna '{col}' no está en el DataFrame\")\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "columns_to_encode = [\n",
    "    'action_categorical_0', 'action_categorical_1', 'action_categorical_2', \n",
    "    'action_categorical_3', 'action_categorical_4',\n",
    "    'auction_categorical_0', 'auction_categorical_11', 'auction_categorical_12', \n",
    "    'auction_categorical_3', 'auction_categorical_7', 'auction_categorical_8', \n",
    "    'auction_categorical_9', 'creative_categorical_0', \n",
    "    'creative_categorical_11', 'creative_categorical_12', 'creative_categorical_2', \n",
    "    'creative_categorical_4', 'creative_categorical_5', 'creative_categorical_6', \n",
    "    'creative_categorical_7', 'creative_categorical_8', 'creative_categorical_9', \n",
    "    'device_id_type'\n",
    "]\n",
    "\n",
    "# Columnas con listas para OHE\n",
    "list_columns = ['action_list_1', 'action_list_2', 'auction_list_0']\n",
    "\n",
    "# Aplicar codificación one-hot a las columnas categóricas\n",
    "data_OHE_Cat = apply_one_hot_encoding(data50k, columns_to_encode)\n",
    "\n",
    "\n",
    "\n",
    "# Aplicar OHE a las columnas de listas\n",
    "data_OHE_Cat_List = apply_multilabel_ohe(data_OHE_Cat, list_columns)\n",
    "#Valid_OHE_Cat_List = apply_multilabel_ohe(Valid_OHE_Cat, list_columns)\n",
    "\n",
    "\n",
    "print(\"DataFrame después del MultiLabel OHE:\")\n",
    "print(f\"Forma después de codificar train: {data_OHE_Cat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en la columna Label: [0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_age</th>\n",
       "      <th>auction_bidfloor</th>\n",
       "      <th>auction_time</th>\n",
       "      <th>creative_height</th>\n",
       "      <th>creative_width</th>\n",
       "      <th>has_video</th>\n",
       "      <th>timezone_offset</th>\n",
       "      <th>action_categorical_0_11b7af3d</th>\n",
       "      <th>action_categorical_0_604d011f</th>\n",
       "      <th>action_categorical_0_6b5513a4</th>\n",
       "      <th>...</th>\n",
       "      <th>IAB9-30</th>\n",
       "      <th>IAB7-2</th>\n",
       "      <th>IAB7-10</th>\n",
       "      <th>IAB10-3</th>\n",
       "      <th>IAB6-4</th>\n",
       "      <th>IAB19-3</th>\n",
       "      <th>IAB6-9</th>\n",
       "      <th>IAB18</th>\n",
       "      <th>IAB17-39</th>\n",
       "      <th>lifestyle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666392</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.516143e+09</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675483</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>1.516539e+09</td>\n",
       "      <td>250.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381289</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.516390e+09</td>\n",
       "      <td>250.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174376</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.559000</td>\n",
       "      <td>1.516374e+09</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220432</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.516380e+09</td>\n",
       "      <td>250.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631126</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.516479e+09</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72307</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.516206e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90504</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.516473e+09</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521083</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.516557e+09</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747801</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.516263e+09</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 48995 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        auction_age  auction_bidfloor  auction_time  creative_height  \\\n",
       "666392          NaN          0.020000  1.516143e+09             50.0   \n",
       "675483          NaN          0.310000  1.516539e+09            250.0   \n",
       "381289          NaN          0.070000  1.516390e+09            250.0   \n",
       "174376          NaN          0.559000  1.516374e+09             50.0   \n",
       "220432         31.0          0.020000  1.516380e+09            250.0   \n",
       "...             ...               ...           ...              ...   \n",
       "631126          NaN          0.100000  1.516479e+09             50.0   \n",
       "72307          39.0          0.850000  1.516206e+09              NaN   \n",
       "90504          16.0          0.020000  1.516473e+09             50.0   \n",
       "521083          NaN          0.307692  1.516557e+09             50.0   \n",
       "747801         34.0          0.020000  1.516263e+09             50.0   \n",
       "\n",
       "        creative_width  has_video  timezone_offset  \\\n",
       "666392           320.0      False              1.0   \n",
       "675483           300.0      False              4.0   \n",
       "381289           300.0      False              1.0   \n",
       "174376           320.0      False              1.0   \n",
       "220432           300.0      False              4.0   \n",
       "...                ...        ...              ...   \n",
       "631126           320.0      False              1.0   \n",
       "72307              NaN      False              1.0   \n",
       "90504            320.0      False              1.0   \n",
       "521083           320.0      False              1.0   \n",
       "747801           320.0      False             10.0   \n",
       "\n",
       "        action_categorical_0_11b7af3d  action_categorical_0_604d011f  \\\n",
       "666392                              0                              0   \n",
       "675483                              0                              1   \n",
       "381289                              0                              0   \n",
       "174376                              1                              0   \n",
       "220432                              0                              1   \n",
       "...                               ...                            ...   \n",
       "631126                              0                              0   \n",
       "72307                               0                              0   \n",
       "90504                               0                              0   \n",
       "521083                              0                              0   \n",
       "747801                              0                              0   \n",
       "\n",
       "        action_categorical_0_6b5513a4  ...  IAB9-30  IAB7-2  IAB7-10  IAB10-3  \\\n",
       "666392                              0  ...        0       0        0        0   \n",
       "675483                              0  ...        0       0        0        0   \n",
       "381289                              0  ...        0       0        0        0   \n",
       "174376                              0  ...        0       0        0        0   \n",
       "220432                              0  ...        0       0        0        0   \n",
       "...                               ...  ...      ...     ...      ...      ...   \n",
       "631126                              0  ...        0       0        0        0   \n",
       "72307                               0  ...        0       0        0        0   \n",
       "90504                               0  ...        0       0        0        0   \n",
       "521083                              0  ...        0       0        0        0   \n",
       "747801                              0  ...        0       0        0        0   \n",
       "\n",
       "        IAB6-4  IAB19-3  IAB6-9  IAB18  IAB17-39  lifestyle  \n",
       "666392       0        0       0      0         0          0  \n",
       "675483       0        0       0      0         0          0  \n",
       "381289       0        0       0      0         0          0  \n",
       "174376       0        0       0      0         0          0  \n",
       "220432       0        0       0      0         0          0  \n",
       "...        ...      ...     ...    ...       ...        ...  \n",
       "631126       0        0       0      0         0          0  \n",
       "72307        0        0       0      0         0          1  \n",
       "90504        0        0       0      0         0          0  \n",
       "521083       0        0       0      0         0          0  \n",
       "747801       0        0       0      0         0          0  \n",
       "\n",
       "[50000 rows x 48995 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_OHE_Cat_List[['Label']].copy() # Usamos copy para no modificar un view abajo, ya que genera un warning.\n",
    "y\n",
    "unique_labels = data_OHE_Cat_List['Label'].unique()\n",
    "print(f'Valores únicos en la columna Label: {unique_labels}')\n",
    "y[y['Label'] == 0. ] = 0\n",
    "y[y['Label'] == 1.] = 1\n",
    "y['Label'] = y['Label'].fillna(0)\n",
    "y['Label'] = y['Label'].astype(int)\n",
    "X = data_OHE_Cat_List.drop('Label', axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n",
      "Cantidad de datos de entrenamiento: 35000\n",
      "Cantidad de datos de validación: 7500\n",
      "Cantidad de datos de prueba: 7500\n",
      "Cantidad de datos de train: 35000\n",
      "Cantidad de datos de validación: 7500\n",
      "Cantidad de datos de test: 7500\n"
     ]
    }
   ],
   "source": [
    "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y,\n",
    "                                                  train_size=0.7,\n",
    "                                                  random_state=42,\n",
    "                                                  stratify=y)\n",
    "print(\"ready\")\n",
    "\n",
    "# Dividir el resto en validación y prueba\n",
    "X_val, X_test, Y_val, y_test = train_test_split(X_tmp, y_tmp,\n",
    "                                                train_size=0.5,\n",
    "                                                random_state=42,\n",
    "                                                stratify=y_tmp)\n",
    "\n",
    "print(f'Cantidad de datos de entrenamiento: {len(X_train)}')\n",
    "print(f'Cantidad de datos de validación: {len(X_val)}')\n",
    "print(f'Cantidad de datos de prueba: {len(X_test)}')\n",
    "\n",
    "val_test_size = 0.3 # Proporción de la suma del test de validación y del de test.\n",
    "X_train, X_tmp, Y_train, Y_tmp = train_test_split(X, y,\n",
    "                                                  train_size = 0.7,\n",
    "                                                  random_state = 42,\n",
    "                                                  stratify = y)\n",
    "\n",
    "X_val, X_test, Y_val, y_test = train_test_split(X_tmp, y_tmp,\n",
    "                                                train_size=0.5,\n",
    "                                                random_state= 42,\n",
    "                                                stratify=y_tmp)\n",
    "print(f'Cantidad de datos de train: {len(X_train)}')\n",
    "print(f'Cantidad de datos de validación: {len(X_val)}')\n",
    "print(f'Cantidad de datos de test: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auction_age                                float64\n",
      "auction_bidfloor                           float64\n",
      "auction_time                               float64\n",
      "creative_height                            float64\n",
      "creative_width                             float64\n",
      "                                        ...       \n",
      "auction_categorical_0_6e069bec    Sparse[int64, 0]\n",
      "auction_categorical_0_6e74066f    Sparse[int64, 0]\n",
      "auction_categorical_0_6e9ad7fd    Sparse[int64, 0]\n",
      "auction_categorical_0_6eba7824    Sparse[int64, 0]\n",
      "auction_categorical_0_707fbf0e    Sparse[int64, 0]\n",
      "Length: 900, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes.head(900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGBoost classifier\n",
    "clf_xgb = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                            seed=42,\n",
    "                            eval_metric='auc',  # You can also use 'logloss' for binary classification\n",
    "                            use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:04:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.75379\n",
      "[1]\tvalidation_0-auc:0.75646\n",
      "[2]\tvalidation_0-auc:0.77839\n",
      "[3]\tvalidation_0-auc:0.78123\n",
      "[4]\tvalidation_0-auc:0.78308\n",
      "[5]\tvalidation_0-auc:0.78306\n",
      "[6]\tvalidation_0-auc:0.78143\n",
      "[7]\tvalidation_0-auc:0.79876\n",
      "[8]\tvalidation_0-auc:0.80058\n",
      "[9]\tvalidation_0-auc:0.79576\n",
      "[10]\tvalidation_0-auc:0.79668\n",
      "[11]\tvalidation_0-auc:0.79923\n",
      "[12]\tvalidation_0-auc:0.79970\n",
      "[13]\tvalidation_0-auc:0.80074\n",
      "[14]\tvalidation_0-auc:0.79801\n",
      "[15]\tvalidation_0-auc:0.79550\n",
      "[16]\tvalidation_0-auc:0.79689\n",
      "[17]\tvalidation_0-auc:0.79732\n",
      "[18]\tvalidation_0-auc:0.79828\n",
      "[19]\tvalidation_0-auc:0.79928\n",
      "[20]\tvalidation_0-auc:0.80062\n",
      "[21]\tvalidation_0-auc:0.80168\n",
      "[22]\tvalidation_0-auc:0.79984\n",
      "[23]\tvalidation_0-auc:0.80029\n",
      "[24]\tvalidation_0-auc:0.80053\n",
      "[25]\tvalidation_0-auc:0.80152\n",
      "[26]\tvalidation_0-auc:0.80294\n",
      "[27]\tvalidation_0-auc:0.80248\n",
      "[28]\tvalidation_0-auc:0.80150\n",
      "[29]\tvalidation_0-auc:0.79903\n",
      "[30]\tvalidation_0-auc:0.79959\n",
      "[31]\tvalidation_0-auc:0.80020\n",
      "[32]\tvalidation_0-auc:0.80016\n",
      "[33]\tvalidation_0-auc:0.80025\n",
      "[34]\tvalidation_0-auc:0.80042\n",
      "[35]\tvalidation_0-auc:0.80008\n",
      "[36]\tvalidation_0-auc:0.79968\n",
      "[37]\tvalidation_0-auc:0.79981\n",
      "[38]\tvalidation_0-auc:0.79955\n",
      "[39]\tvalidation_0-auc:0.79903\n",
      "[40]\tvalidation_0-auc:0.79981\n",
      "[41]\tvalidation_0-auc:0.80067\n",
      "[42]\tvalidation_0-auc:0.80134\n",
      "[43]\tvalidation_0-auc:0.80140\n",
      "[44]\tvalidation_0-auc:0.80130\n",
      "[45]\tvalidation_0-auc:0.80086\n",
      "[46]\tvalidation_0-auc:0.79925\n",
      "[47]\tvalidation_0-auc:0.79735\n",
      "[48]\tvalidation_0-auc:0.79682\n",
      "[49]\tvalidation_0-auc:0.79747\n",
      "[50]\tvalidation_0-auc:0.79764\n",
      "[51]\tvalidation_0-auc:0.79738\n",
      "[52]\tvalidation_0-auc:0.79773\n",
      "[53]\tvalidation_0-auc:0.79796\n",
      "[54]\tvalidation_0-auc:0.79850\n",
      "[55]\tvalidation_0-auc:0.79874\n",
      "[56]\tvalidation_0-auc:0.79987\n",
      "[57]\tvalidation_0-auc:0.80049\n",
      "[58]\tvalidation_0-auc:0.80011\n",
      "[59]\tvalidation_0-auc:0.79977\n",
      "[60]\tvalidation_0-auc:0.79937\n",
      "[61]\tvalidation_0-auc:0.79939\n",
      "[62]\tvalidation_0-auc:0.79907\n",
      "[63]\tvalidation_0-auc:0.79725\n",
      "[64]\tvalidation_0-auc:0.79691\n",
      "[65]\tvalidation_0-auc:0.79606\n",
      "[66]\tvalidation_0-auc:0.79612\n",
      "[67]\tvalidation_0-auc:0.79699\n",
      "[68]\tvalidation_0-auc:0.79692\n",
      "[69]\tvalidation_0-auc:0.79784\n",
      "[70]\tvalidation_0-auc:0.79774\n",
      "[71]\tvalidation_0-auc:0.79758\n",
      "[72]\tvalidation_0-auc:0.79796\n",
      "[73]\tvalidation_0-auc:0.79834\n",
      "[74]\tvalidation_0-auc:0.79898\n",
      "[75]\tvalidation_0-auc:0.79875\n",
      "[76]\tvalidation_0-auc:0.79886\n",
      "[77]\tvalidation_0-auc:0.79917\n",
      "[78]\tvalidation_0-auc:0.79830\n",
      "[79]\tvalidation_0-auc:0.79830\n",
      "[80]\tvalidation_0-auc:0.79816\n",
      "[81]\tvalidation_0-auc:0.79809\n",
      "[82]\tvalidation_0-auc:0.79830\n",
      "[83]\tvalidation_0-auc:0.79813\n",
      "[84]\tvalidation_0-auc:0.79717\n",
      "[85]\tvalidation_0-auc:0.79665\n",
      "[86]\tvalidation_0-auc:0.79742\n",
      "[87]\tvalidation_0-auc:0.79700\n",
      "[88]\tvalidation_0-auc:0.79696\n",
      "[89]\tvalidation_0-auc:0.79727\n",
      "[90]\tvalidation_0-auc:0.79679\n",
      "[91]\tvalidation_0-auc:0.79469\n",
      "[92]\tvalidation_0-auc:0.79246\n",
      "[93]\tvalidation_0-auc:0.79208\n",
      "[94]\tvalidation_0-auc:0.78931\n",
      "[95]\tvalidation_0-auc:0.79154\n",
      "[96]\tvalidation_0-auc:0.79167\n",
      "[97]\tvalidation_0-auc:0.79203\n",
      "[98]\tvalidation_0-auc:0.79074\n",
      "[99]\tvalidation_0-auc:0.78952\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "X_train_sparse = sp.csr_matrix(X_train)\n",
    "X_val_sparse = sp.csr_matrix(X_val)\n",
    "X_test_sparse = sp.csr_matrix(X_test)\n",
    "\n",
    "# Ahora puedes usar XGBoost con matrices sparse\n",
    "clf_xgb.fit(X_train_sparse, y_train, eval_set=[(X_val_sparse, Y_val)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m eval_data_sparse \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(eval_data_imputed)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Hacer predicciones con el modelo XGBoost entrenado\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m y_preds \u001b[38;5;241m=\u001b[39m \u001b[43mclf_xgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_data_sparse\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Obtener la probabilidad de la clase positiva (1)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Crear el DataFrame para el envío a Kaggle\u001b[39;00m\n\u001b[1;32m     24\u001b[0m submission_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: eval_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_preds\n\u001b[1;32m     27\u001b[0m })\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/sklearn.py:1644\u001b[0m, in \u001b[0;36mXGBClassifier.predict_proba\u001b[0;34m(self, X, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1642\u001b[0m     class_prob \u001b[38;5;241m=\u001b[39m softmax(raw_predt, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m class_prob\n\u001b[0;32m-> 1644\u001b[0m class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _cls_predict_proba(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_, class_probs, np\u001b[38;5;241m.\u001b[39mvstack)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/sklearn.py:1186\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1186\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[1;32m   1187\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   1188\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[1;32m   1189\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1190\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1191\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[1;32m   1192\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[1;32m   1193\u001b[0m         )\n\u001b[1;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[1;32m   1195\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/TD6/lib/python3.12/site-packages/xgboost/sklearn.py:805\u001b[0m, in \u001b[0;36mXGBModel.get_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__():\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[0;32m--> 805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to call fit or load_model beforehand\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\n",
      "\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Cargar los datos de evaluación (test)\n",
    "eval_data = pd.read_csv(\"/Users/ionikullock/Desktop/UTDT-Tecnología Digital/TD VI/Trabajo práctico 2/Datos/ctr_test.csv\")\n",
    "\n",
    "\n",
    "# Procesar los datos de test (seleccionando solo las columnas numéricas, como en el entrenamiento)\n",
    "eval_data_num = eval_data.select_dtypes(include='number')\n",
    "\n",
    "# Imputar valores faltantes, si es necesario (usa la misma estrategia que en entrenamiento)\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "eval_data_imputed = imputer.fit_transform(eval_data_num.drop(columns=[\"id\"]))\n",
    "\n",
    "# Convertir los datos a formato sparse para ser usados en el modelo XGBoost\n",
    "eval_data_sparse = sp.csr_matrix(eval_data_imputed)\n",
    "\n",
    "# Hacer predicciones con el modelo XGBoost entrenado\n",
    "y_preds = clf_xgb.predict_proba(eval_data_sparse)[:, 1]  # Obtener la probabilidad de la clase positiva (1)\n",
    "\n",
    "# Crear el DataFrame para el envío a Kaggle\n",
    "submission_df = pd.DataFrame({\n",
    "    \"id\": eval_data[\"id\"],\n",
    "    \"Label\": y_preds\n",
    "})\n",
    "\n",
    "# Convertir el ID a entero (según el formato requerido por Kaggle)\n",
    "submission_df[\"id\"] = submission_df[\"id\"].astype(int)\n",
    "\n",
    "# Guardar el archivo CSV para enviar a Kaggle\n",
    "submission_df.to_csv(\"xgboost_model_submission.csv\", sep=\",\", index=False)\n",
    "\n",
    "print(\"Archivo de predicción creado: xgboost_model_submission.csv\")\n",
    "\n",
    "print(\"Archivo de predicción creado: xgboost_model_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TD6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
